{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy17qMHOmD3j",
        "outputId": "478c51f3-44e4-4796-b9b5-7582e02985ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 Datasets preparation\n"
      ],
      "metadata": {
        "id": "6Tk4gjRIlFoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1 load libary"
      ],
      "metadata": {
        "id": "74t8GN2QRK3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "np.random.seed(5328)\n",
        "tf.random.set_seed(5328)"
      ],
      "metadata": {
        "id": "m54A82bDlF_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Load datasets"
      ],
      "metadata": {
        "id": "fZLS6Tmxk3Z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_F3 = np.load('/content/drive/MyDrive/5328data/FashionMNIST0.3.npz')\n",
        "\n",
        "# Load the training, validation, and test data\n",
        "Xtr_F3 = dataset_F3['X_tr']\n",
        "Str_F3 = dataset_F3['S_tr']\n",
        "Xts_F3 = dataset_F3['X_ts']\n",
        "Yts_F3 = dataset_F3['Y_ts']\n",
        "\n",
        "print(\"Training and Validation Data Shape:\", Xtr_F3.shape)\n",
        "print(\"Noisy labels Shape:\", Str_F3.shape)\n",
        "print(\"Test Data Shape:\", Xts_F3.shape)\n",
        "print(\"Test Labels Shape:\", Yts_F3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjd3SIdbjTLY",
        "outputId": "88b9b9b3-5b5e-4623-f975-237f48eb6f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Validation Data Shape: (24000, 28, 28)\n",
            "Noisy labels Shape: (24000,)\n",
            "Test Data Shape: (4000, 28, 28)\n",
            "Test Labels Shape: (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_F6 = np.load('/content/drive/MyDrive/5328data/FashionMNIST0.6.npz')\n",
        "\n",
        "# Load the training, validation, and test data\n",
        "Xtr_F6 = dataset_F6['X_tr']\n",
        "Str_F6 = dataset_F6['S_tr']\n",
        "Xts_F6 = dataset_F6['X_ts']\n",
        "Yts_F6 = dataset_F6['Y_ts']\n",
        "\n",
        "print(\"Training and Validation Data Shape:\", Xtr_F6.shape)\n",
        "print(\"Noisy Labels Shape:\", Str_F6.shape)\n",
        "print(\"Test Data Shape:\", Xts_F6.shape)\n",
        "print(\"Test Labels Shape:\", Yts_F6.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG2YTb-djTXh",
        "outputId": "3315d0e8-193b-4c05-93ae-442728337562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Validation Data Shape: (24000, 28, 28)\n",
            "Noisy Labels Shape: (24000,)\n",
            "Test Data Shape: (4000, 28, 28)\n",
            "Test Labels Shape: (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_C10 = np.load('/content/drive/MyDrive/5328data/CIFAR10.npz')\n",
        "\n",
        "# Load the training, validation, and test data\n",
        "Xtr_C10 = dataset_C10['X_tr']\n",
        "Str_C10 = dataset_C10['S_tr']\n",
        "Xts_C10 = dataset_C10['X_ts']\n",
        "Yts_C10 = dataset_C10['Y_ts']\n",
        "\n",
        "print(\"Training and Validation Data Shape:\", Xtr_C10.shape)\n",
        "print(\"Noisy labels Shape:\", Str_C10.shape)\n",
        "print(\"Test Data Shape:\", Xts_C10.shape)\n",
        "print(\"Test Labels Shape:\", Yts_C10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55zK1UFPjIEF",
        "outputId": "00a077db-6f84-4921-abd0-02321ea8ebce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Validation Data Shape: (20000, 32, 32, 3)\n",
            "Noisy labels Shape: (20000,)\n",
            "Test Data Shape: (4000, 32, 32, 3)\n",
            "Test Labels Shape: (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Display Images in datasets"
      ],
      "metadata": {
        "id": "TYYtcVXfkxXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(images, labels, num_images=5):\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i+1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f\"Label: {labels[i]}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_images(Xtr_F6, Str_F6, num_images=5)\n",
        "display_images(Xtr_F3, Str_F3, num_images=5)\n",
        "display_images(Xtr_C10, Str_C10, num_images=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EuXTwywIkwsI",
        "outputId": "03000a56-010b-4a36-986b-9e0f1a5d4d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vB7peMTYRO66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Image Classification with known Flip Rates"
      ],
      "metadata": {
        "id": "BWjgP-YLk7zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix_FashionMNIST03 = [[0.7, 0.3, 0, 0],\n",
        "                    [0, 0.7, 0.3, 0],\n",
        "                    [0, 0, 0.7, 0.3],\n",
        "                    [0.3, 0, 0, 0.7]]\n",
        "\n",
        "transition_matrix_FashionMNIST06 = [[0.4, 0.2, 0.2, 0.2],\n",
        "                    [0.2, 0.4, 0.2, 0.2],\n",
        "                    [0.2, 0.2, 0.4, 0.2],\n",
        "                    [0.2, 0.2, 0.2, 0.4]]"
      ],
      "metadata": {
        "id": "-Tj9lMl_4cVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 CNN for FashionMNIST0.6 and FashionMNIST0.3"
      ],
      "metadata": {
        "id": "0tjQKtACMHaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1 CNN without transition matrix for FashionMNIST0.6 and FashionMNIST0.3"
      ],
      "metadata": {
        "id": "EB7z6VvILwnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CNN Model for 28x28 grayscale images\n",
        "class CNN28x28(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN28x28, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 input channel for grayscale\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)  # Adjust based on the output size after pooling\n",
        "        self.fc2 = nn.Linear(512, 4)  # Assuming 4 classes for F3 and F6 datasets\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # First convolution + pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Second convolution + pooling\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))  # Fully connected layer\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Define the standard cross-entropy loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_and_evaluate(model_class, X, y, epochs=10, batch_size=64):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "\n",
        "    # Convert data to PyTorch Tensor\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
        "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    # Calculate mean and standard deviation from training data\n",
        "    mean = X_train_tensor.mean()\n",
        "    std = X_train_tensor.std()\n",
        "\n",
        "    # Normalize the training and validation data using the mean and standard deviation of the training set\n",
        "    X_train_tensor = (X_train_tensor - mean) / std\n",
        "    X_val_tensor = (X_val_tensor - mean) / std\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_class().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, targets in train_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)  # Standard cross-entropy loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy = evaluate_model(model, val_loader)\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    return model, mean, std\n",
        "\n",
        "# Function to evaluate model accuracy\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in val_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "def evaluate_on_test_set(model, X_test, y_test, mean, std, batch_size=64):\n",
        "    # Convert the test data to a PyTorch Tensor and normalize it using the mean and standard deviation of the training set\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "    X_test_tensor = (X_test_tensor - mean) / std  # Normalize using the mean and standard deviation of the training set\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Main function to train multiple times and calculate mean accuracy and standard deviation\n",
        "def train_multiple_times_with_test(model_class, X, y, X_test, y_test, num_trials=10, epochs=10):\n",
        "    test_accuracy_list = []\n",
        "\n",
        "    for trial in range(num_trials):\n",
        "        print(f\"\\nTrial {trial+1}/{num_trials}\")\n",
        "        # Train the model and get the mean and standard deviation of the training data\n",
        "        model, mean, std = train_and_evaluate(model_class, X, y, epochs=epochs)\n",
        "        # Evaluate the model on the test set using the mean and standard deviation of the training set\n",
        "        test_accuracy = evaluate_on_test_set(model, X_test, y_test, mean, std)\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "        print(f\"Trial {trial+1} Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    mean_test_accuracy = np.mean(test_accuracy_list)\n",
        "    std_test_accuracy = np.std(test_accuracy_list)\n",
        "\n",
        "    print(f\"\\nAverage Test Accuracy after {num_trials} trials: {mean_test_accuracy:.2f}%\")\n",
        "    print(f\"Standard Deviation of Test Accuracy: {std_test_accuracy:.2f}%\")\n",
        "\n",
        "    return mean_test_accuracy, std_test_accuracy"
      ],
      "metadata": {
        "id": "oDn5KFy3D9o1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training on the FashionMNIST0.3 dataset"
      ],
      "metadata": {
        "id": "iuKzCG7TRWYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test_accuracy, std_test_accuracy = train_multiple_times_with_test(CNN28x28, Xtr_F3, Str_F3, Xts_F3, Yts_F3, num_trials=10, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShMk7gbsHQG5",
        "outputId": "426d652d-5642-4edc-93d4-f4b5d6f7c8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7866\n",
            "Epoch 2/5, Loss: 0.7084\n",
            "Epoch 3/5, Loss: 0.6883\n",
            "Epoch 4/5, Loss: 0.6749\n",
            "Epoch 5/5, Loss: 0.6556\n",
            "Validation Accuracy: 66.50%\n",
            "Test Accuracy: 94.88%\n",
            "Trial 1 Test Accuracy: 94.88%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7897\n",
            "Epoch 2/5, Loss: 0.7142\n",
            "Epoch 3/5, Loss: 0.6922\n",
            "Epoch 4/5, Loss: 0.6789\n",
            "Epoch 5/5, Loss: 0.6630\n",
            "Validation Accuracy: 67.83%\n",
            "Test Accuracy: 95.38%\n",
            "Trial 2 Test Accuracy: 95.38%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7950\n",
            "Epoch 2/5, Loss: 0.7129\n",
            "Epoch 3/5, Loss: 0.6940\n",
            "Epoch 4/5, Loss: 0.6729\n",
            "Epoch 5/5, Loss: 0.6595\n",
            "Validation Accuracy: 66.77%\n",
            "Test Accuracy: 93.85%\n",
            "Trial 3 Test Accuracy: 93.85%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7888\n",
            "Epoch 2/5, Loss: 0.7126\n",
            "Epoch 3/5, Loss: 0.6925\n",
            "Epoch 4/5, Loss: 0.6764\n",
            "Epoch 5/5, Loss: 0.6614\n",
            "Validation Accuracy: 67.90%\n",
            "Test Accuracy: 95.22%\n",
            "Trial 4 Test Accuracy: 95.22%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7898\n",
            "Epoch 2/5, Loss: 0.7115\n",
            "Epoch 3/5, Loss: 0.6906\n",
            "Epoch 4/5, Loss: 0.6753\n",
            "Epoch 5/5, Loss: 0.6615\n",
            "Validation Accuracy: 68.90%\n",
            "Test Accuracy: 95.55%\n",
            "Trial 5 Test Accuracy: 95.55%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.8015\n",
            "Epoch 2/5, Loss: 0.7137\n",
            "Epoch 3/5, Loss: 0.6922\n",
            "Epoch 4/5, Loss: 0.6738\n",
            "Epoch 5/5, Loss: 0.6576\n",
            "Validation Accuracy: 66.75%\n",
            "Test Accuracy: 93.97%\n",
            "Trial 6 Test Accuracy: 93.97%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.8195\n",
            "Epoch 2/5, Loss: 0.7213\n",
            "Epoch 3/5, Loss: 0.6985\n",
            "Epoch 4/5, Loss: 0.6816\n",
            "Epoch 5/5, Loss: 0.6676\n",
            "Validation Accuracy: 67.15%\n",
            "Test Accuracy: 93.97%\n",
            "Trial 7 Test Accuracy: 93.97%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.8013\n",
            "Epoch 2/5, Loss: 0.7100\n",
            "Epoch 3/5, Loss: 0.6880\n",
            "Epoch 4/5, Loss: 0.6733\n",
            "Epoch 5/5, Loss: 0.6579\n",
            "Validation Accuracy: 66.60%\n",
            "Test Accuracy: 94.08%\n",
            "Trial 8 Test Accuracy: 94.08%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7954\n",
            "Epoch 2/5, Loss: 0.7119\n",
            "Epoch 3/5, Loss: 0.6908\n",
            "Epoch 4/5, Loss: 0.6754\n",
            "Epoch 5/5, Loss: 0.6563\n",
            "Validation Accuracy: 67.48%\n",
            "Test Accuracy: 94.67%\n",
            "Trial 9 Test Accuracy: 94.67%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.7826\n",
            "Epoch 2/5, Loss: 0.7057\n",
            "Epoch 3/5, Loss: 0.6864\n",
            "Epoch 4/5, Loss: 0.6706\n",
            "Epoch 5/5, Loss: 0.6522\n",
            "Validation Accuracy: 64.92%\n",
            "Test Accuracy: 92.67%\n",
            "Trial 10 Test Accuracy: 92.67%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 94.42%\n",
            "Standard Deviation of Test Accuracy: 0.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training on the FashionMNIST0.6 dataset"
      ],
      "metadata": {
        "id": "-vJJ4veXRZZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test_accuracy, std_test_accuracy = train_multiple_times_with_test(CNN28x28, Xtr_F6, Str_F6, Xts_F6, Yts_F6, num_trials=10, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXGAT9Q2EXgB",
        "outputId": "e545abca-25c3-438f-f6e5-e3f5f717f773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3600\n",
            "Epoch 2/5, Loss: 1.3468\n",
            "Epoch 3/5, Loss: 1.3434\n",
            "Epoch 4/5, Loss: 1.3401\n",
            "Epoch 5/5, Loss: 1.3364\n",
            "Validation Accuracy: 37.62%\n",
            "Test Accuracy: 91.12%\n",
            "Trial 1 Test Accuracy: 91.12%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3610\n",
            "Epoch 2/5, Loss: 1.3491\n",
            "Epoch 3/5, Loss: 1.3447\n",
            "Epoch 4/5, Loss: 1.3411\n",
            "Epoch 5/5, Loss: 1.3368\n",
            "Validation Accuracy: 38.31%\n",
            "Test Accuracy: 90.95%\n",
            "Trial 2 Test Accuracy: 90.95%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3558\n",
            "Epoch 2/5, Loss: 1.3464\n",
            "Epoch 3/5, Loss: 1.3424\n",
            "Epoch 4/5, Loss: 1.3387\n",
            "Epoch 5/5, Loss: 1.3330\n",
            "Validation Accuracy: 37.27%\n",
            "Test Accuracy: 90.70%\n",
            "Trial 3 Test Accuracy: 90.70%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3655\n",
            "Epoch 2/5, Loss: 1.3485\n",
            "Epoch 3/5, Loss: 1.3452\n",
            "Epoch 4/5, Loss: 1.3439\n",
            "Epoch 5/5, Loss: 1.3398\n",
            "Validation Accuracy: 38.46%\n",
            "Test Accuracy: 90.72%\n",
            "Trial 4 Test Accuracy: 90.72%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3630\n",
            "Epoch 2/5, Loss: 1.3475\n",
            "Epoch 3/5, Loss: 1.3441\n",
            "Epoch 4/5, Loss: 1.3421\n",
            "Epoch 5/5, Loss: 1.3386\n",
            "Validation Accuracy: 37.94%\n",
            "Test Accuracy: 92.35%\n",
            "Trial 5 Test Accuracy: 92.35%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3602\n",
            "Epoch 2/5, Loss: 1.3470\n",
            "Epoch 3/5, Loss: 1.3453\n",
            "Epoch 4/5, Loss: 1.3413\n",
            "Epoch 5/5, Loss: 1.3379\n",
            "Validation Accuracy: 38.19%\n",
            "Test Accuracy: 91.53%\n",
            "Trial 6 Test Accuracy: 91.53%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3593\n",
            "Epoch 2/5, Loss: 1.3465\n",
            "Epoch 3/5, Loss: 1.3432\n",
            "Epoch 4/5, Loss: 1.3405\n",
            "Epoch 5/5, Loss: 1.3364\n",
            "Validation Accuracy: 37.29%\n",
            "Test Accuracy: 91.60%\n",
            "Trial 7 Test Accuracy: 91.60%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3628\n",
            "Epoch 2/5, Loss: 1.3486\n",
            "Epoch 3/5, Loss: 1.3445\n",
            "Epoch 4/5, Loss: 1.3406\n",
            "Epoch 5/5, Loss: 1.3377\n",
            "Validation Accuracy: 38.46%\n",
            "Test Accuracy: 91.00%\n",
            "Trial 8 Test Accuracy: 91.00%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3642\n",
            "Epoch 2/5, Loss: 1.3485\n",
            "Epoch 3/5, Loss: 1.3449\n",
            "Epoch 4/5, Loss: 1.3426\n",
            "Epoch 5/5, Loss: 1.3382\n",
            "Validation Accuracy: 38.92%\n",
            "Test Accuracy: 91.95%\n",
            "Trial 9 Test Accuracy: 91.95%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3582\n",
            "Epoch 2/5, Loss: 1.3460\n",
            "Epoch 3/5, Loss: 1.3432\n",
            "Epoch 4/5, Loss: 1.3401\n",
            "Epoch 5/5, Loss: 1.3373\n",
            "Validation Accuracy: 38.65%\n",
            "Test Accuracy: 92.05%\n",
            "Trial 10 Test Accuracy: 92.05%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 91.40%\n",
            "Standard Deviation of Test Accuracy: 0.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1 CNN with transition matrix for FashionMNIST0.6 and FashionMNIST0.3"
      ],
      "metadata": {
        "id": "YteHhudBMHAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function with the transformation matrix\n",
        "def noisy_loss_function(preds, targets, transition_matrix):\n",
        "    T = torch.tensor(transition_matrix, dtype=torch.float32).to(preds.device)\n",
        "    # Model's log probabilities for true labels\n",
        "    log_probs = F.log_softmax(preds, dim=1)\n",
        "    # Compute the loss considering the transition matrix\n",
        "    loss = -torch.mean(torch.sum(T[targets] * log_probs, dim=1))\n",
        "    return loss\n",
        "\n",
        "def train_and_evaluate(model_class, X, y, transition_matrix, epochs=10, batch_size=64):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "\n",
        "    # Convert data to PyTorch Tensor\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
        "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    # Calculate mean and standard deviation from training data\n",
        "    mean = X_train_tensor.mean()\n",
        "    std = X_train_tensor.std()\n",
        "\n",
        "    # Normalize the training and validation data using the mean and standard deviation of the training set\n",
        "    X_train_tensor = (X_train_tensor - mean) / std\n",
        "    X_val_tensor = (X_val_tensor - mean) / std\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_class().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, targets in train_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = noisy_loss_function(outputs, targets, transition_matrix)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy = evaluate_model(model, val_loader)\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    return model, mean, std\n",
        "def train_multiple_times_with_test_withT(model_class, X, y, X_test, y_test, transition_matrix, num_trials=10, epochs=10):\n",
        "    test_accuracy_list = []\n",
        "\n",
        "    for trial in range(num_trials):\n",
        "        print(f\"\\nTrial {trial+1}/{num_trials}\")\n",
        "        # Train the model and get the mean and standard deviation of the training data\n",
        "        model, mean, std = train_and_evaluate(model_class, X, y, transition_matrix, epochs=epochs)\n",
        "        # Evaluate the model on the test set using the mean and standard deviation of the training set\n",
        "        test_accuracy = evaluate_on_test_set(model, X_test, y_test, mean, std)\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "        print(f\"Trial {trial+1} Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    mean_test_accuracy = np.mean(test_accuracy_list)\n",
        "    std_test_accuracy = np.std(test_accuracy_list)\n",
        "\n",
        "    print(f\"\\nAverage Test Accuracy after {num_trials} trials: {mean_test_accuracy:.2f}%\")\n",
        "    print(f\"Standard Deviation of Test Accuracy: {std_test_accuracy:.2f}%\")\n",
        "\n",
        "    return mean_test_accuracy, std_test_accuracy"
      ],
      "metadata": {
        "id": "hnXRZE0hxAts"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training on the FashionMNIST0.3 dataset"
      ],
      "metadata": {
        "id": "0RBioTRALjBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the FashionMNIST0.3 dataset\n",
        "mean_test_accuracy_03, std_test_accuracy_03 = train_multiple_times_with_test_withT(\n",
        "    CNN28x28, Xtr_F3, Str_F3, Xts_F3, Yts_F3, transition_matrix_FashionMNIST03, num_trials=10, epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwyINPOU2NxS",
        "outputId": "682e6522-02a1-45ec-8fc3-b4a85efe86ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0506\n",
            "Epoch 2/5, Loss: 0.9936\n",
            "Epoch 3/5, Loss: 0.9810\n",
            "Epoch 4/5, Loss: 0.9725\n",
            "Epoch 5/5, Loss: 0.9653\n",
            "Validation Accuracy: 54.73%\n",
            "Test Accuracy: 66.90%\n",
            "Trial 1 Test Accuracy: 66.90%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0355\n",
            "Epoch 2/5, Loss: 0.9918\n",
            "Epoch 3/5, Loss: 0.9788\n",
            "Epoch 4/5, Loss: 0.9702\n",
            "Epoch 5/5, Loss: 0.9625\n",
            "Validation Accuracy: 60.29%\n",
            "Test Accuracy: 78.05%\n",
            "Trial 2 Test Accuracy: 78.05%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0460\n",
            "Epoch 2/5, Loss: 0.9933\n",
            "Epoch 3/5, Loss: 0.9811\n",
            "Epoch 4/5, Loss: 0.9729\n",
            "Epoch 5/5, Loss: 0.9644\n",
            "Validation Accuracy: 63.04%\n",
            "Test Accuracy: 82.83%\n",
            "Trial 3 Test Accuracy: 82.83%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0480\n",
            "Epoch 2/5, Loss: 0.9926\n",
            "Epoch 3/5, Loss: 0.9806\n",
            "Epoch 4/5, Loss: 0.9699\n",
            "Epoch 5/5, Loss: 0.9623\n",
            "Validation Accuracy: 63.62%\n",
            "Test Accuracy: 83.15%\n",
            "Trial 4 Test Accuracy: 83.15%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0508\n",
            "Epoch 2/5, Loss: 0.9925\n",
            "Epoch 3/5, Loss: 0.9809\n",
            "Epoch 4/5, Loss: 0.9729\n",
            "Epoch 5/5, Loss: 0.9659\n",
            "Validation Accuracy: 65.38%\n",
            "Test Accuracy: 90.17%\n",
            "Trial 5 Test Accuracy: 90.17%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0404\n",
            "Epoch 2/5, Loss: 0.9935\n",
            "Epoch 3/5, Loss: 0.9795\n",
            "Epoch 4/5, Loss: 0.9736\n",
            "Epoch 5/5, Loss: 0.9664\n",
            "Validation Accuracy: 59.71%\n",
            "Test Accuracy: 73.70%\n",
            "Trial 6 Test Accuracy: 73.70%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0426\n",
            "Epoch 2/5, Loss: 0.9931\n",
            "Epoch 3/5, Loss: 0.9807\n",
            "Epoch 4/5, Loss: 0.9715\n",
            "Epoch 5/5, Loss: 0.9632\n",
            "Validation Accuracy: 60.35%\n",
            "Test Accuracy: 77.70%\n",
            "Trial 7 Test Accuracy: 77.70%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0405\n",
            "Epoch 2/5, Loss: 0.9906\n",
            "Epoch 3/5, Loss: 0.9784\n",
            "Epoch 4/5, Loss: 0.9695\n",
            "Epoch 5/5, Loss: 0.9603\n",
            "Validation Accuracy: 63.25%\n",
            "Test Accuracy: 85.55%\n",
            "Trial 8 Test Accuracy: 85.55%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0377\n",
            "Epoch 2/5, Loss: 0.9949\n",
            "Epoch 3/5, Loss: 0.9818\n",
            "Epoch 4/5, Loss: 0.9714\n",
            "Epoch 5/5, Loss: 0.9613\n",
            "Validation Accuracy: 66.17%\n",
            "Test Accuracy: 90.45%\n",
            "Trial 9 Test Accuracy: 90.45%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0447\n",
            "Epoch 2/5, Loss: 0.9957\n",
            "Epoch 3/5, Loss: 0.9810\n",
            "Epoch 4/5, Loss: 0.9717\n",
            "Epoch 5/5, Loss: 0.9631\n",
            "Validation Accuracy: 58.33%\n",
            "Test Accuracy: 71.33%\n",
            "Trial 10 Test Accuracy: 71.33%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 79.98%\n",
            "Standard Deviation of Test Accuracy: 7.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training on the FashionMNIST0.6 dataset"
      ],
      "metadata": {
        "id": "CWIZxZToMRmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the FashionMNIST0.6 dataset\n",
        "mean_test_accuracy_06, std_test_accuracy_06 = train_multiple_times_with_test_withT(\n",
        "    CNN28x28, Xtr_F6, Str_F6, Xts_F6, Yts_F6, transition_matrix_FashionMNIST06, num_trials=10, epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEd3-cK4m7cq",
        "outputId": "c40c80bc-4e7c-4203-8aeb-9371008642b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3868\n",
            "Epoch 2/5, Loss: 1.3847\n",
            "Epoch 3/5, Loss: 1.3845\n",
            "Epoch 4/5, Loss: 1.3843\n",
            "Epoch 5/5, Loss: 1.3841\n",
            "Validation Accuracy: 38.21%\n",
            "Test Accuracy: 91.35%\n",
            "Trial 1 Test Accuracy: 91.35%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3867\n",
            "Epoch 2/5, Loss: 1.3846\n",
            "Epoch 3/5, Loss: 1.3845\n",
            "Epoch 4/5, Loss: 1.3843\n",
            "Epoch 5/5, Loss: 1.3842\n",
            "Validation Accuracy: 38.15%\n",
            "Test Accuracy: 90.10%\n",
            "Trial 2 Test Accuracy: 90.10%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3870\n",
            "Epoch 2/5, Loss: 1.3847\n",
            "Epoch 3/5, Loss: 1.3845\n",
            "Epoch 4/5, Loss: 1.3844\n",
            "Epoch 5/5, Loss: 1.3843\n",
            "Validation Accuracy: 37.77%\n",
            "Test Accuracy: 90.50%\n",
            "Trial 3 Test Accuracy: 90.50%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3858\n",
            "Epoch 2/5, Loss: 1.3848\n",
            "Epoch 3/5, Loss: 1.3846\n",
            "Epoch 4/5, Loss: 1.3845\n",
            "Epoch 5/5, Loss: 1.3844\n",
            "Validation Accuracy: 38.19%\n",
            "Test Accuracy: 87.95%\n",
            "Trial 4 Test Accuracy: 87.95%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3873\n",
            "Epoch 2/5, Loss: 1.3846\n",
            "Epoch 3/5, Loss: 1.3843\n",
            "Epoch 4/5, Loss: 1.3841\n",
            "Epoch 5/5, Loss: 1.3839\n",
            "Validation Accuracy: 36.23%\n",
            "Test Accuracy: 88.10%\n",
            "Trial 5 Test Accuracy: 88.10%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3870\n",
            "Epoch 2/5, Loss: 1.3847\n",
            "Epoch 3/5, Loss: 1.3846\n",
            "Epoch 4/5, Loss: 1.3844\n",
            "Epoch 5/5, Loss: 1.3843\n",
            "Validation Accuracy: 38.85%\n",
            "Test Accuracy: 89.80%\n",
            "Trial 6 Test Accuracy: 89.80%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3875\n",
            "Epoch 2/5, Loss: 1.3847\n",
            "Epoch 3/5, Loss: 1.3845\n",
            "Epoch 4/5, Loss: 1.3844\n",
            "Epoch 5/5, Loss: 1.3842\n",
            "Validation Accuracy: 38.81%\n",
            "Test Accuracy: 90.47%\n",
            "Trial 7 Test Accuracy: 90.47%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3878\n",
            "Epoch 2/5, Loss: 1.3848\n",
            "Epoch 3/5, Loss: 1.3846\n",
            "Epoch 4/5, Loss: 1.3844\n",
            "Epoch 5/5, Loss: 1.3843\n",
            "Validation Accuracy: 39.42%\n",
            "Test Accuracy: 90.17%\n",
            "Trial 8 Test Accuracy: 90.17%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3871\n",
            "Epoch 2/5, Loss: 1.3847\n",
            "Epoch 3/5, Loss: 1.3844\n",
            "Epoch 4/5, Loss: 1.3843\n",
            "Epoch 5/5, Loss: 1.3841\n",
            "Validation Accuracy: 38.29%\n",
            "Test Accuracy: 89.90%\n",
            "Trial 9 Test Accuracy: 89.90%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (19200, 28, 28)\n",
            "y_train shape: (19200,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.3867\n",
            "Epoch 2/5, Loss: 1.3848\n",
            "Epoch 3/5, Loss: 1.3846\n",
            "Epoch 4/5, Loss: 1.3845\n",
            "Epoch 5/5, Loss: 1.3843\n",
            "Validation Accuracy: 39.33%\n",
            "Test Accuracy: 91.10%\n",
            "Trial 10 Test Accuracy: 91.10%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 89.94%\n",
            "Standard Deviation of Test Accuracy: 1.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Logistic Regression for FashionMNIST0.6 and FashionMNIST0.3"
      ],
      "metadata": {
        "id": "ubaBOHarMVrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(X_tr, S_tr, X_ts, Y_ts, T1):\n",
        "    # Initialize lists to store accuracy results for validation and test sets\n",
        "    acc_valid_list = []\n",
        "    acc_test_without_T_list = []\n",
        "    acc_test_with_T_list = []\n",
        "\n",
        "    # Run multiple training and evaluation iterations\n",
        "    for i in range(10):\n",
        "        # Split the training data into training and validation sets\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X_tr, S_tr, test_size=0.2, shuffle=True)\n",
        "\n",
        "        # Flatten the data to convert image data into a 2D matrix\n",
        "        X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "        X_valid_flat = X_valid.reshape(X_valid.shape[0], -1)\n",
        "        X_ts_flat = X_ts.reshape(X_ts.shape[0], -1)\n",
        "\n",
        "        # Initialize and train the LogisticRegression model\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train_flat, y_train)\n",
        "\n",
        "        # Predict and calculate accuracy on the validation set\n",
        "        y_pred = model.predict(X_valid_flat)\n",
        "        acc_valid = accuracy_score(y_pred, y_valid)\n",
        "        acc_valid_list.append(acc_valid)\n",
        "\n",
        "        # Predict and calculate accuracy on the test set (without transition matrix)\n",
        "        y_pred = model.predict(X_ts_flat)\n",
        "        acc_test_without_T = accuracy_score(y_pred, Y_ts)\n",
        "        acc_test_without_T_list.append(acc_test_without_T)\n",
        "\n",
        "        # Calculate accuracy on the test set using the transition matrix\n",
        "        prob = model.predict_proba(X_ts_flat)\n",
        "        prob = np.dot(np.linalg.inv(T1), prob.T).T  # Apply transition matrix\n",
        "        y_pred = np.argmax(prob, axis=1)\n",
        "        acc_test_with_T = accuracy_score(y_pred, Y_ts)\n",
        "        acc_test_with_T_list.append(acc_test_with_T)\n",
        "\n",
        "        # Print accuracy for each iteration\n",
        "        print(\"Current epoch: %d, Accuracy on valid set: %.4f%%, accuracy on test set without Transition Matrix: %.4f%%, accuracy on test set with Transition Matrix: %.4f%%\"\n",
        "              % (i+1, acc_valid * 100, acc_test_without_T * 100, acc_test_with_T * 100))\n",
        "\n",
        "    # Calculate and print the mean and standard deviation for validation and test set accuracies\n",
        "    print(\"Mean on valid set: %.4f, Mean on test set without Transition Matrix: %.4f, Mean on test set with Transition Matrix: %.4f\"\n",
        "          % (np.mean(acc_valid_list), np.mean(acc_test_without_T_list), np.mean(acc_test_with_T_list)))\n",
        "\n",
        "    print(\"Std on valid set: %.4f, Std on test set without Transition Matrix: %.4f, Std on test set with Transition Matrix: %.4f\"\n",
        "          % (np.std(acc_valid_list), np.std(acc_test_without_T_list), np.std(acc_test_with_T_list)))"
      ],
      "metadata": {
        "id": "DGPAzvy3XcZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Training on the FashionMNIST0.3 dataset"
      ],
      "metadata": {
        "id": "qZgx5VfUMj0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_03 = logistic(Xtr_F3, Str_F3, Xts_F3, Yts_F3, transition_matrix_FashionMNIST03)\n",
        "logistic_03"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L5Lv2eiYzhq",
        "outputId": "b3820f1a-36b2-4ace-be56-6a4134f57372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current epoch: 1, Accuracy on valid set: 62.5625%, accuracy on test set without Transition Matrix: 85.2750%, accuracy on test set with Transition Matrix: 80.1250%\n",
            "Current epoch: 2, Accuracy on valid set: 62.5625%, accuracy on test set without Transition Matrix: 84.8250%, accuracy on test set with Transition Matrix: 78.9000%\n",
            "Current epoch: 3, Accuracy on valid set: 63.2500%, accuracy on test set without Transition Matrix: 84.8500%, accuracy on test set with Transition Matrix: 78.9500%\n",
            "Current epoch: 4, Accuracy on valid set: 63.2917%, accuracy on test set without Transition Matrix: 84.3250%, accuracy on test set with Transition Matrix: 79.2000%\n",
            "Current epoch: 5, Accuracy on valid set: 62.5833%, accuracy on test set without Transition Matrix: 85.0750%, accuracy on test set with Transition Matrix: 78.9250%\n",
            "Current epoch: 6, Accuracy on valid set: 63.3333%, accuracy on test set without Transition Matrix: 84.1500%, accuracy on test set with Transition Matrix: 78.4750%\n",
            "Current epoch: 7, Accuracy on valid set: 63.6667%, accuracy on test set without Transition Matrix: 85.2750%, accuracy on test set with Transition Matrix: 80.0000%\n",
            "Current epoch: 8, Accuracy on valid set: 63.6875%, accuracy on test set without Transition Matrix: 85.6250%, accuracy on test set with Transition Matrix: 80.1500%\n",
            "Current epoch: 9, Accuracy on valid set: 64.2708%, accuracy on test set without Transition Matrix: 85.5000%, accuracy on test set with Transition Matrix: 79.9000%\n",
            "Current epoch: 10, Accuracy on valid set: 63.4583%, accuracy on test set without Transition Matrix: 84.9750%, accuracy on test set with Transition Matrix: 79.8000%\n",
            "Mean on valid set: 0.6327, Mean on test set without Transition Matrix: 0.8499, Mean on test set with Transition Matrix: 0.7944\n",
            "Std on valid set: 0.0053, Std on test set without Transition Matrix: 0.0045, Std on test set with Transition Matrix: 0.0058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Training on the FashionMNIST0.6 dataset"
      ],
      "metadata": {
        "id": "hfYmZpYyMj2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_06 = logistic(Xtr_F6, Str_F6, Xts_F6, Yts_F6, transition_matrix_FashionMNIST06)\n",
        "logistic_06"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGCbQemnMSG",
        "outputId": "154c45ee-c063-42ec-fc5b-696dde979d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current epoch: 1, Accuracy on valid set: 36.3125%, accuracy on test set without Transition Matrix: 78.8500%, accuracy on test set with Transition Matrix: 78.8500%\n",
            "Current epoch: 2, Accuracy on valid set: 36.0625%, accuracy on test set without Transition Matrix: 79.4750%, accuracy on test set with Transition Matrix: 79.4750%\n",
            "Current epoch: 3, Accuracy on valid set: 35.8750%, accuracy on test set without Transition Matrix: 79.6250%, accuracy on test set with Transition Matrix: 79.6250%\n",
            "Current epoch: 4, Accuracy on valid set: 35.7708%, accuracy on test set without Transition Matrix: 77.9250%, accuracy on test set with Transition Matrix: 77.9250%\n",
            "Current epoch: 5, Accuracy on valid set: 34.8958%, accuracy on test set without Transition Matrix: 79.5500%, accuracy on test set with Transition Matrix: 79.5500%\n",
            "Current epoch: 6, Accuracy on valid set: 36.1458%, accuracy on test set without Transition Matrix: 76.8500%, accuracy on test set with Transition Matrix: 76.8500%\n",
            "Current epoch: 7, Accuracy on valid set: 35.0417%, accuracy on test set without Transition Matrix: 77.8500%, accuracy on test set with Transition Matrix: 77.8500%\n",
            "Current epoch: 8, Accuracy on valid set: 35.3542%, accuracy on test set without Transition Matrix: 78.6250%, accuracy on test set with Transition Matrix: 78.6250%\n",
            "Current epoch: 9, Accuracy on valid set: 35.2708%, accuracy on test set without Transition Matrix: 75.9000%, accuracy on test set with Transition Matrix: 75.9000%\n",
            "Current epoch: 10, Accuracy on valid set: 34.6875%, accuracy on test set without Transition Matrix: 78.0750%, accuracy on test set with Transition Matrix: 78.0750%\n",
            "Mean on valid set: 0.3554, Mean on test set without Transition Matrix: 0.7827, Mean on test set with Transition Matrix: 0.7827\n",
            "Std on valid set: 0.0054, Std on test set without Transition Matrix: 0.0116, Std on test set with Transition Matrix: 0.0116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Estimate the transition matrix for CIFAR dataset"
      ],
      "metadata": {
        "id": "nFs3HZE47dwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generalized_cross_entropy(y_true, y_pred, q=0.5):\n",
        "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[1])\n",
        "    loss = (1 - tf.pow(tf.reduce_sum(y_true * y_pred, axis=-1), q)) / q\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def build_robust_cnn(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss=lambda y_true, y_pred: generalized_cross_entropy(y_true, y_pred, q=0.5),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def analyze_confidence_distribution(X, model, num_classes):\n",
        "    predictions = model.predict(X / 255.0)\n",
        "    confidence_percentiles = {60: [], 65: [],70: [], 75: [], 80: [], 85: [], 90: [], 95: [], 98: []}\n",
        "\n",
        "    for class_label in range(num_classes):\n",
        "        class_probs = predictions[:, class_label]\n",
        "        for percentile in confidence_percentiles.keys():\n",
        "            threshold = np.percentile(class_probs, percentile)\n",
        "            confidence_percentiles[percentile].append(threshold)\n",
        "\n",
        "    print(\"Confidence thresholds per percentile:\")\n",
        "    for percentile, thresholds in confidence_percentiles.items():\n",
        "        print(f\"{percentile}%: {thresholds}\")\n",
        "\n",
        "    return confidence_percentiles\n",
        "\n",
        "\n",
        "def estimate_transition_matrix_with_anchors(X, y_noisy, model, num_classes, adaptive_thresholds):\n",
        "    y_pred = model.predict(X / 255.0)\n",
        "    transition_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        mask = (y_noisy == i) & (np.max(y_pred, axis=1) > adaptive_thresholds[i])\n",
        "        for j in range(num_classes):\n",
        "            transition_matrix[i, j] = np.mean(mask & (np.argmax(y_pred, axis=1) == j))\n",
        "\n",
        "    transition_matrix /= transition_matrix.sum(axis=1, keepdims=True)\n",
        "    print(\"Diagonal values of estimated transition matrix:\", np.diag(transition_matrix))\n",
        "    return transition_matrix\n",
        "\n",
        "def calculate_mse(actual, estimated):\n",
        "    return np.mean((actual - estimated) ** 2)\n",
        "\n",
        "\n",
        "def load_dataset(filepath):\n",
        "    data = np.load(filepath)\n",
        "    return data['X_tr'], data['S_tr'], data['X_ts'], data['Y_ts']\n",
        "\n",
        "cifar_filepath = '/content/drive/MyDrive/5328data/CIFAR10.npz'\n",
        "Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = load_dataset(cifar_filepath)"
      ],
      "metadata": {
        "id": "wD-Wh7TGJ_AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_robust_cnn(input_shape=(32, 32, 3), num_classes=4)\n",
        "class_weights = {\n",
        "    0: 1.4,\n",
        "    1: 1.3,\n",
        "    2: 4.5,\n",
        "    3: 3.0\n",
        "}\n",
        "model.fit(Xtr_cifar / 255.0, Str_cifar, epochs=80, batch_size=32, validation_split=0.2, class_weight=class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVulp3s4KGFR",
        "outputId": "25f380e5-d214-45df-a1cf-657da3028029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 72ms/step - accuracy: 0.3659 - loss: 2.6774 - val_accuracy: 0.5008 - val_loss: 0.8358\n",
            "Epoch 2/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 68ms/step - accuracy: 0.5248 - loss: 1.9938 - val_accuracy: 0.6043 - val_loss: 0.6735\n",
            "Epoch 3/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.5674 - loss: 1.8539 - val_accuracy: 0.6045 - val_loss: 0.6768\n",
            "Epoch 4/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.5837 - loss: 1.7731 - val_accuracy: 0.6033 - val_loss: 0.6816\n",
            "Epoch 5/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 76ms/step - accuracy: 0.5991 - loss: 1.7332 - val_accuracy: 0.6273 - val_loss: 0.6470\n",
            "Epoch 6/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - accuracy: 0.6076 - loss: 1.6914 - val_accuracy: 0.6285 - val_loss: 0.6382\n",
            "Epoch 7/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 67ms/step - accuracy: 0.6166 - loss: 1.6613 - val_accuracy: 0.6248 - val_loss: 0.6512\n",
            "Epoch 8/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.6254 - loss: 1.6252 - val_accuracy: 0.6223 - val_loss: 0.6535\n",
            "Epoch 9/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 73ms/step - accuracy: 0.6352 - loss: 1.5952 - val_accuracy: 0.6457 - val_loss: 0.6108\n",
            "Epoch 10/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 67ms/step - accuracy: 0.6377 - loss: 1.5689 - val_accuracy: 0.6488 - val_loss: 0.6118\n",
            "Epoch 11/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 70ms/step - accuracy: 0.6421 - loss: 1.5552 - val_accuracy: 0.6590 - val_loss: 0.5929\n",
            "Epoch 12/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 67ms/step - accuracy: 0.6454 - loss: 1.5479 - val_accuracy: 0.6582 - val_loss: 0.6018\n",
            "Epoch 13/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.6536 - loss: 1.5141 - val_accuracy: 0.6625 - val_loss: 0.5937\n",
            "Epoch 14/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 70ms/step - accuracy: 0.6620 - loss: 1.4890 - val_accuracy: 0.6612 - val_loss: 0.5996\n",
            "Epoch 15/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 68ms/step - accuracy: 0.6656 - loss: 1.4892 - val_accuracy: 0.6708 - val_loss: 0.5834\n",
            "Epoch 16/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 72ms/step - accuracy: 0.6592 - loss: 1.4947 - val_accuracy: 0.6635 - val_loss: 0.5923\n",
            "Epoch 17/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 69ms/step - accuracy: 0.6671 - loss: 1.4664 - val_accuracy: 0.6725 - val_loss: 0.5759\n",
            "Epoch 18/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.6693 - loss: 1.4571 - val_accuracy: 0.6715 - val_loss: 0.5754\n",
            "Epoch 19/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.6744 - loss: 1.4258 - val_accuracy: 0.6727 - val_loss: 0.5721\n",
            "Epoch 20/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 72ms/step - accuracy: 0.6800 - loss: 1.4183 - val_accuracy: 0.6740 - val_loss: 0.5773\n",
            "Epoch 21/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 67ms/step - accuracy: 0.6780 - loss: 1.4267 - val_accuracy: 0.6745 - val_loss: 0.5665\n",
            "Epoch 22/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.6853 - loss: 1.3988 - val_accuracy: 0.6678 - val_loss: 0.5801\n",
            "Epoch 23/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.6875 - loss: 1.3956 - val_accuracy: 0.6760 - val_loss: 0.5589\n",
            "Epoch 24/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 72ms/step - accuracy: 0.6825 - loss: 1.3957 - val_accuracy: 0.6825 - val_loss: 0.5615\n",
            "Epoch 25/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 80ms/step - accuracy: 0.6922 - loss: 1.3769 - val_accuracy: 0.6805 - val_loss: 0.5623\n",
            "Epoch 26/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - accuracy: 0.6967 - loss: 1.3584 - val_accuracy: 0.6795 - val_loss: 0.5595\n",
            "Epoch 27/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 71ms/step - accuracy: 0.6980 - loss: 1.3570 - val_accuracy: 0.6775 - val_loss: 0.5652\n",
            "Epoch 28/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 71ms/step - accuracy: 0.6957 - loss: 1.3561 - val_accuracy: 0.6895 - val_loss: 0.5501\n",
            "Epoch 29/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 67ms/step - accuracy: 0.6989 - loss: 1.3412 - val_accuracy: 0.6798 - val_loss: 0.5621\n",
            "Epoch 30/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 70ms/step - accuracy: 0.7012 - loss: 1.3348 - val_accuracy: 0.6755 - val_loss: 0.5620\n",
            "Epoch 31/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 73ms/step - accuracy: 0.7040 - loss: 1.3277 - val_accuracy: 0.6867 - val_loss: 0.5457\n",
            "Epoch 32/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 70ms/step - accuracy: 0.7006 - loss: 1.3363 - val_accuracy: 0.6852 - val_loss: 0.5542\n",
            "Epoch 33/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.7106 - loss: 1.2949 - val_accuracy: 0.6817 - val_loss: 0.5625\n",
            "Epoch 34/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.7095 - loss: 1.2957 - val_accuracy: 0.6930 - val_loss: 0.5430\n",
            "Epoch 35/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 72ms/step - accuracy: 0.7107 - loss: 1.2888 - val_accuracy: 0.6908 - val_loss: 0.5473\n",
            "Epoch 36/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.7121 - loss: 1.2827 - val_accuracy: 0.6890 - val_loss: 0.5489\n",
            "Epoch 37/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.7111 - loss: 1.2800 - val_accuracy: 0.6948 - val_loss: 0.5436\n",
            "Epoch 38/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.7167 - loss: 1.2707 - val_accuracy: 0.6902 - val_loss: 0.5459\n",
            "Epoch 39/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 73ms/step - accuracy: 0.7179 - loss: 1.2574 - val_accuracy: 0.6895 - val_loss: 0.5484\n",
            "Epoch 40/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.7136 - loss: 1.2743 - val_accuracy: 0.6870 - val_loss: 0.5584\n",
            "Epoch 41/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.7258 - loss: 1.2444 - val_accuracy: 0.6923 - val_loss: 0.5537\n",
            "Epoch 42/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.7247 - loss: 1.2381 - val_accuracy: 0.6942 - val_loss: 0.5419\n",
            "Epoch 43/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 72ms/step - accuracy: 0.7277 - loss: 1.2349 - val_accuracy: 0.6940 - val_loss: 0.5444\n",
            "Epoch 44/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 67ms/step - accuracy: 0.7265 - loss: 1.2269 - val_accuracy: 0.6985 - val_loss: 0.5381\n",
            "Epoch 45/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.7291 - loss: 1.2258 - val_accuracy: 0.6960 - val_loss: 0.5454\n",
            "Epoch 46/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.7268 - loss: 1.2264 - val_accuracy: 0.6942 - val_loss: 0.5506\n",
            "Epoch 47/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 71ms/step - accuracy: 0.7237 - loss: 1.2327 - val_accuracy: 0.6957 - val_loss: 0.5470\n",
            "Epoch 48/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 68ms/step - accuracy: 0.7309 - loss: 1.2169 - val_accuracy: 0.6948 - val_loss: 0.5409\n",
            "Epoch 49/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.7309 - loss: 1.2034 - val_accuracy: 0.6995 - val_loss: 0.5369\n",
            "Epoch 50/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 73ms/step - accuracy: 0.7331 - loss: 1.2013 - val_accuracy: 0.7028 - val_loss: 0.5374\n",
            "Epoch 51/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.7347 - loss: 1.1909 - val_accuracy: 0.7003 - val_loss: 0.5362\n",
            "Epoch 52/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.7290 - loss: 1.2096 - val_accuracy: 0.6995 - val_loss: 0.5373\n",
            "Epoch 53/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.7383 - loss: 1.1822 - val_accuracy: 0.6992 - val_loss: 0.5312\n",
            "Epoch 54/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 73ms/step - accuracy: 0.7413 - loss: 1.1730 - val_accuracy: 0.6990 - val_loss: 0.5333\n",
            "Epoch 55/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 68ms/step - accuracy: 0.7423 - loss: 1.1722 - val_accuracy: 0.6915 - val_loss: 0.5440\n",
            "Epoch 56/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.7382 - loss: 1.1777 - val_accuracy: 0.6933 - val_loss: 0.5454\n",
            "Epoch 57/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 67ms/step - accuracy: 0.7455 - loss: 1.1604 - val_accuracy: 0.7040 - val_loss: 0.5313\n",
            "Epoch 58/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 74ms/step - accuracy: 0.7361 - loss: 1.1716 - val_accuracy: 0.7015 - val_loss: 0.5359\n",
            "Epoch 59/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 68ms/step - accuracy: 0.7448 - loss: 1.1598 - val_accuracy: 0.6963 - val_loss: 0.5426\n",
            "Epoch 60/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 69ms/step - accuracy: 0.7385 - loss: 1.1677 - val_accuracy: 0.6995 - val_loss: 0.5386\n",
            "Epoch 61/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.7510 - loss: 1.1374 - val_accuracy: 0.6965 - val_loss: 0.5360\n",
            "Epoch 62/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 77ms/step - accuracy: 0.7510 - loss: 1.1359 - val_accuracy: 0.7000 - val_loss: 0.5402\n",
            "Epoch 63/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 68ms/step - accuracy: 0.7475 - loss: 1.1449 - val_accuracy: 0.7030 - val_loss: 0.5333\n",
            "Epoch 64/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.7505 - loss: 1.1382 - val_accuracy: 0.7017 - val_loss: 0.5342\n",
            "Epoch 65/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.7499 - loss: 1.1312 - val_accuracy: 0.7065 - val_loss: 0.5271\n",
            "Epoch 66/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 72ms/step - accuracy: 0.7513 - loss: 1.1246 - val_accuracy: 0.7025 - val_loss: 0.5318\n",
            "Epoch 67/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 68ms/step - accuracy: 0.7507 - loss: 1.1195 - val_accuracy: 0.7053 - val_loss: 0.5325\n",
            "Epoch 68/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.7566 - loss: 1.1058 - val_accuracy: 0.7050 - val_loss: 0.5275\n",
            "Epoch 69/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.7556 - loss: 1.1002 - val_accuracy: 0.6942 - val_loss: 0.5446\n",
            "Epoch 70/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 72ms/step - accuracy: 0.7591 - loss: 1.1025 - val_accuracy: 0.7010 - val_loss: 0.5327\n",
            "Epoch 71/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 71ms/step - accuracy: 0.7599 - loss: 1.0937 - val_accuracy: 0.7085 - val_loss: 0.5275\n",
            "Epoch 72/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 68ms/step - accuracy: 0.7578 - loss: 1.0977 - val_accuracy: 0.7042 - val_loss: 0.5313\n",
            "Epoch 73/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.7588 - loss: 1.0973 - val_accuracy: 0.7007 - val_loss: 0.5337\n",
            "Epoch 74/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 71ms/step - accuracy: 0.7620 - loss: 1.0828 - val_accuracy: 0.7065 - val_loss: 0.5316\n",
            "Epoch 75/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 71ms/step - accuracy: 0.7589 - loss: 1.0860 - val_accuracy: 0.7053 - val_loss: 0.5337\n",
            "Epoch 76/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 68ms/step - accuracy: 0.7653 - loss: 1.0739 - val_accuracy: 0.7040 - val_loss: 0.5347\n",
            "Epoch 77/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.7640 - loss: 1.0876 - val_accuracy: 0.6925 - val_loss: 0.5532\n",
            "Epoch 78/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 74ms/step - accuracy: 0.7591 - loss: 1.0920 - val_accuracy: 0.6877 - val_loss: 0.5576\n",
            "Epoch 79/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 68ms/step - accuracy: 0.7691 - loss: 1.0616 - val_accuracy: 0.7063 - val_loss: 0.5363\n",
            "Epoch 80/80\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.7618 - loss: 1.0824 - val_accuracy: 0.7000 - val_loss: 0.5320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78847dae1420>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_percentiles = analyze_confidence_distribution(Xtr_cifar, model, num_classes=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge6Fnp_-KGHR",
        "outputId": "f9fec126-e10e-4598-aa78-869dfd45df7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step\n",
            "Confidence thresholds per percentile:\n",
            "60%: [0.005607647821307179, 0.005800474621355529, 0.024678124859929068, 0.007576218247413635]\n",
            "65%: [0.016589014511555433, 0.018278471659868956, 0.0696876745671034, 0.024858949799090625]\n",
            "70%: [0.06388312652707091, 0.06893820613622635, 0.20563744455575933, 0.09163216650485984]\n",
            "75%: [0.36411990970373154, 0.5988323241472244, 0.5307441800832748, 0.3972421959042549]\n",
            "80%: [0.890276944637299, 0.9850674152374268, 0.8682319045066835, 0.8316138386726379]\n",
            "85%: [0.9806143045425415, 0.998487102985382, 0.9673098742961883, 0.974389961361885]\n",
            "90%: [0.9963570952415466, 0.9998656272888183, 0.9920318305492402, 0.9962726950645447]\n",
            "95%: [0.9995132565498352, 0.9999927937984466, 0.9988174736499786, 0.9996961414813995]\n",
            "98%: [0.9999240064620971, 0.9999995827674866, 0.9997778081893921, 0.9999769425392151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust adaptive thresholds\n",
        "adaptive_thresholds = [confidence_percentiles[80][0],\n",
        "                       confidence_percentiles[80][1],\n",
        "                       confidence_percentiles[80][2],\n",
        "                       confidence_percentiles[85][3]]"
      ],
      "metadata": {
        "id": "pcLPJ2zUKGJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 CIFAR10"
      ],
      "metadata": {
        "id": "v9EofE_mOPq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate transition matrix for CIFAR10\n",
        "estimated_matrix_with_anchors = estimate_transition_matrix_with_anchors(Xtr_cifar, Str_cifar, model, num_classes=4, adaptive_thresholds=adaptive_thresholds)\n",
        "print(\"Estimated Transition Matrix with Anchors for CIFAR10:\")\n",
        "print(estimated_matrix_with_anchors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuTDoScwKKgV",
        "outputId": "550ee347-6ed1-4842-d29d-c62137d555d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step\n",
            "Diagonal values of estimated transition matrix: [0.85       0.91763158 0.80985745 0.88961039]\n",
            "Estimated Transition Matrix with Anchors for CIFAR10:\n",
            "[[0.85       0.018      0.02725    0.10475   ]\n",
            " [0.07763158 0.91763158 0.00210526 0.00263158]\n",
            " [0.02464363 0.14085528 0.80985745 0.02464363]\n",
            " [0.01093643 0.00341763 0.09603554 0.88961039]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 MSE for FashionMNIST0.3"
      ],
      "metadata": {
        "id": "5JL52ekDNpSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FashionMNIST_03_filepath = '/content/drive/MyDrive/5328data/FashionMNIST0.3.npz'\n",
        "Xtr_03, Str_03, Xts_03, Yts_03 = load_dataset(FashionMNIST_03_filepath)\n",
        "\n",
        "FashionMNIST_06_filepath = '/content/drive/MyDrive/5328data/FashionMNIST0.6.npz'\n",
        "Xtr_06, Str_06, Xts_06, Yts_06 = load_dataset(FashionMNIST_06_filepath)\n",
        "\n",
        "Xtr_03 = np.expand_dims(Xtr_03, axis=-1)\n",
        "Xts_03 = np.expand_dims(Xts_03, axis=-1)\n",
        "Xtr_06 = np.expand_dims(Xtr_06, axis=-1)\n",
        "Xts_06 = np.expand_dims(Xts_06, axis=-1)\n",
        "\n",
        "num_classes = 4\n",
        "input_shape = (28, 28, 1)"
      ],
      "metadata": {
        "id": "MtXnvNAhOonN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_03 = build_robust_cnn(input_shape, num_classes)\n",
        "model_03.fit(Xtr_03 / 255.0, Str_03, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2iCXOICNocL",
        "outputId": "3c1def00-6776-4974-91c4-6cc5ffea6c91"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.4500 - loss: 0.9213 - val_accuracy: 0.6465 - val_loss: 0.6174\n",
            "Epoch 2/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.5985 - loss: 0.6803 - val_accuracy: 0.6617 - val_loss: 0.5783\n",
            "Epoch 3/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 56ms/step - accuracy: 0.6191 - loss: 0.6370 - val_accuracy: 0.6615 - val_loss: 0.5667\n",
            "Epoch 4/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.6275 - loss: 0.6206 - val_accuracy: 0.6644 - val_loss: 0.5589\n",
            "Epoch 5/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.6343 - loss: 0.6084 - val_accuracy: 0.6706 - val_loss: 0.5521\n",
            "Epoch 6/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - accuracy: 0.6410 - loss: 0.5985 - val_accuracy: 0.6710 - val_loss: 0.5505\n",
            "Epoch 7/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.6436 - loss: 0.5912 - val_accuracy: 0.6700 - val_loss: 0.5462\n",
            "Epoch 8/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 57ms/step - accuracy: 0.6541 - loss: 0.5814 - val_accuracy: 0.6710 - val_loss: 0.5445\n",
            "Epoch 9/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 52ms/step - accuracy: 0.6552 - loss: 0.5770 - val_accuracy: 0.6723 - val_loss: 0.5427\n",
            "Epoch 10/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.6555 - loss: 0.5746 - val_accuracy: 0.6746 - val_loss: 0.5404\n",
            "Epoch 11/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.6603 - loss: 0.5671 - val_accuracy: 0.6752 - val_loss: 0.5384\n",
            "Epoch 12/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 56ms/step - accuracy: 0.6584 - loss: 0.5655 - val_accuracy: 0.6773 - val_loss: 0.5387\n",
            "Epoch 13/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 53ms/step - accuracy: 0.6611 - loss: 0.5648 - val_accuracy: 0.6769 - val_loss: 0.5359\n",
            "Epoch 14/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - accuracy: 0.6638 - loss: 0.5607 - val_accuracy: 0.6758 - val_loss: 0.5364\n",
            "Epoch 15/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.6638 - loss: 0.5582 - val_accuracy: 0.6731 - val_loss: 0.5371\n",
            "Epoch 16/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.6646 - loss: 0.5550 - val_accuracy: 0.6767 - val_loss: 0.5343\n",
            "Epoch 17/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 57ms/step - accuracy: 0.6652 - loss: 0.5523 - val_accuracy: 0.6777 - val_loss: 0.5339\n",
            "Epoch 18/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 50ms/step - accuracy: 0.6641 - loss: 0.5522 - val_accuracy: 0.6796 - val_loss: 0.5336\n",
            "Epoch 19/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - accuracy: 0.6680 - loss: 0.5496 - val_accuracy: 0.6800 - val_loss: 0.5321\n",
            "Epoch 20/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 53ms/step - accuracy: 0.6656 - loss: 0.5487 - val_accuracy: 0.6792 - val_loss: 0.5347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3a737b4610>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_percentiles_03 = analyze_confidence_distribution(Xtr_03, model_03, num_classes=4)"
      ],
      "metadata": {
        "id": "wPa5c2anNyhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5238d4e7-db37-4f0f-a4ba-81e2385337a4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step\n",
            "Confidence thresholds per percentile:\n",
            "60%: [0.13651145696640016, 0.11210416704416275, 0.16722135841846464, 0.12896569967269897]\n",
            "65%: [0.1764673709869385, 0.13314802944660187, 0.18646523952484131, 0.16035163253545762]\n",
            "70%: [0.2435815513134002, 0.1623643323779106, 0.21480156481266016, 0.20719595700502394]\n",
            "75%: [0.6053356677293777, 0.2940569818019867, 0.38737712800502777, 0.4451291784644127]\n",
            "80%: [0.8227149724960328, 0.782927417755127, 0.8008086919784546, 0.7609647631645203]\n",
            "85%: [0.8590942919254302, 0.8129684686660766, 0.8475457727909088, 0.8271110355854034]\n",
            "90%: [0.8811225831508637, 0.8326283276081086, 0.878944730758667, 0.8660588085651397]\n",
            "95%: [0.9031992614269256, 0.8544686734676361, 0.911539563536644, 0.9002179384231567]\n",
            "98%: [0.9306588780879975, 0.8932995176315308, 0.9438976085186005, 0.9332187449932099]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust adaptive thresholds\n",
        "adaptive_thresholds_03 = [confidence_percentiles_03[75][0],\n",
        "                       confidence_percentiles_03[75][1],\n",
        "                       confidence_percentiles_03[75][2],\n",
        "                       confidence_percentiles_03[75][3]]\n"
      ],
      "metadata": {
        "id": "wBtljA1bNyte"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate transition matrix for FashionMNIST0.3\n",
        "estimated_matrix_03 = estimate_transition_matrix_with_anchors(Xtr_03, Str_03, model_03, num_classes=4, adaptive_thresholds=adaptive_thresholds_03)\n",
        "print(\"Estimated Transition Matrix with for FashionMNIST0.3\")\n",
        "print(estimated_matrix_03)"
      ],
      "metadata": {
        "id": "xPCQw3pSN3Ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7783a6-7135-4760-b513-43d4c84a832b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step\n",
            "Diagonal values of estimated transition matrix: [0.7014951  0.6886038  0.67557124 0.66001007]\n",
            "Estimated Transition Matrix with for FashionMNIST0.3\n",
            "[[0.7014951  0.00137481 0.01477917 0.28235092]\n",
            " [0.28223925 0.6886038  0.01232922 0.01682772]\n",
            " [0.01310484 0.28830645 0.67557124 0.02301747]\n",
            " [0.0488337  0.00369189 0.28746434 0.66001007]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T_03 = np.array([[0.7, 0.3, 0.0, 0.0],\n",
        "                 [0.0, 0.7, 0.3, 0.0],\n",
        "                 [0.0, 0.0, 0.7, 0.3],\n",
        "                 [0.3, 0.0, 0.0, 0.7]])\n",
        "\n",
        "mse_03 = calculate_mse(T_03, estimated_matrix_03)\n",
        "print(\"MSE for FashionMNIST0.3:\", mse_03)"
      ],
      "metadata": {
        "id": "iNZh_wLON3Sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ab38e5-7229-4f9f-fc84-21849522b1a7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for FashionMNIST0.3: 0.03999298369772684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 MSE for FashionMNIST0.6"
      ],
      "metadata": {
        "id": "5LhLDcXtN758"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelr_06 = build_robust_cnn(input_shape, num_classes)\n",
        "modelr_06.fit(Xtr_06 / 255.0, Str_06, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "IBgiX719N3VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d56152b-a843-48f8-ebd0-c7c3b34998ad"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 0.2843 - loss: 1.1086 - val_accuracy: 0.3650 - val_loss: 0.9895\n",
            "Epoch 2/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 55ms/step - accuracy: 0.3111 - loss: 1.0074 - val_accuracy: 0.3694 - val_loss: 0.9834\n",
            "Epoch 3/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 52ms/step - accuracy: 0.3229 - loss: 1.0009 - val_accuracy: 0.3735 - val_loss: 0.9797\n",
            "Epoch 4/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.3272 - loss: 0.9962 - val_accuracy: 0.3796 - val_loss: 0.9763\n",
            "Epoch 5/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.3293 - loss: 0.9947 - val_accuracy: 0.3738 - val_loss: 0.9758\n",
            "Epoch 6/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.3258 - loss: 0.9957 - val_accuracy: 0.3752 - val_loss: 0.9734\n",
            "Epoch 7/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.3426 - loss: 0.9877 - val_accuracy: 0.3790 - val_loss: 0.9756\n",
            "Epoch 8/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.3438 - loss: 0.9879 - val_accuracy: 0.3762 - val_loss: 0.9738\n",
            "Epoch 9/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.3427 - loss: 0.9871 - val_accuracy: 0.3765 - val_loss: 0.9754\n",
            "Epoch 10/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.3481 - loss: 0.9865 - val_accuracy: 0.3781 - val_loss: 0.9713\n",
            "Epoch 11/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - accuracy: 0.3575 - loss: 0.9838 - val_accuracy: 0.3792 - val_loss: 0.9721\n",
            "Epoch 12/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 52ms/step - accuracy: 0.3505 - loss: 0.9806 - val_accuracy: 0.3802 - val_loss: 0.9711\n",
            "Epoch 13/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.3534 - loss: 0.9817 - val_accuracy: 0.3792 - val_loss: 0.9741\n",
            "Epoch 14/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.3547 - loss: 0.9822 - val_accuracy: 0.3787 - val_loss: 0.9733\n",
            "Epoch 15/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.3551 - loss: 0.9800 - val_accuracy: 0.3777 - val_loss: 0.9718\n",
            "Epoch 16/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 56ms/step - accuracy: 0.3582 - loss: 0.9785 - val_accuracy: 0.3790 - val_loss: 0.9702\n",
            "Epoch 17/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.3604 - loss: 0.9765 - val_accuracy: 0.3810 - val_loss: 0.9704\n",
            "Epoch 18/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 52ms/step - accuracy: 0.3706 - loss: 0.9697 - val_accuracy: 0.3808 - val_loss: 0.9703\n",
            "Epoch 19/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.3629 - loss: 0.9762 - val_accuracy: 0.3817 - val_loss: 0.9712\n",
            "Epoch 20/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.3613 - loss: 0.9748 - val_accuracy: 0.3806 - val_loss: 0.9706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c39fdd2b5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_percentilesr_06 = analyze_confidence_distribution(Xtr_06, modelr_06, num_classes=4)"
      ],
      "metadata": {
        "id": "io_c99ZXN8pD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c63515f-4b1a-4fb2-d449-3356d20756ea"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step\n",
            "Confidence thresholds per percentile:\n",
            "60%: [0.19353025555610656, 0.19575743973255155, 0.19841970801353453, 0.1918679267168045]\n",
            "65%: [0.2160268880426884, 0.21103945672512056, 0.21361173018813134, 0.21094219163060188]\n",
            "70%: [0.24702166020870206, 0.23535901606082915, 0.24607789665460583, 0.24755945056676865]\n",
            "75%: [0.2987321764230728, 0.3033463582396507, 0.3706640303134918, 0.3011891692876816]\n",
            "80%: [0.38431912064552315, 0.48659640550613403, 0.5143499851226807, 0.3717167139053345]\n",
            "85%: [0.46982216238975505, 0.5325966984033584, 0.5952393144369124, 0.430226157605648]\n",
            "90%: [0.5270638108253481, 0.5582360923290253, 0.6666730582714084, 0.48490065336227434]\n",
            "95%: [0.5739411652088164, 0.5886685609817505, 0.7432048201560973, 0.544361475110054]\n",
            "98%: [0.6128067016601563, 0.6172551941871643, 0.8093166875839234, 0.5974730288982393]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust adaptive thresholds\n",
        "adaptive_thresholdsr_06 = [confidence_percentilesr_06[75][0],\n",
        "                       confidence_percentilesr_06[75][1],\n",
        "                       confidence_percentilesr_06[70][2],\n",
        "                       confidence_percentilesr_06[75][3]]"
      ],
      "metadata": {
        "id": "IdQ0LoG5N8ri"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate transition matrix for FashionMNIST0.6\n",
        "estimated_matrix_06 = estimate_transition_matrix_with_anchors(Xtr_06, Str_06, modelr_06, num_classes=4, adaptive_thresholds=adaptive_thresholdsr_06)\n",
        "print(\"Estimated Transition Matrix with for FashionMNIST0.6\")\n",
        "print(estimated_matrix_06)"
      ],
      "metadata": {
        "id": "eAlaNUToN8tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d2236f-9332-4a58-a9a1-3aa7e4ebd6b0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
            "Diagonal values of estimated transition matrix: [0.3735554  0.39931507 0.4015984  0.37714383]\n",
            "Estimated Transition Matrix with for FashionMNIST0.6\n",
            "[[0.3735554  0.20683209 0.2149898  0.20462271]\n",
            " [0.19246575 0.39931507 0.21438356 0.19383562]\n",
            " [0.2001332  0.19314019 0.4015984  0.20512821]\n",
            " [0.19324164 0.20461878 0.22499575 0.37714383]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T_06 = np.array([[0.4, 0.2, 0.2, 0.2],\n",
        "                [0.2, 0.4, 0.2, 0.2],\n",
        "                [0.2, 0.2, 0.4, 0.2],\n",
        "                [0.2, 0.2, 0.2, 0.4]])\n",
        "\n",
        "mse_06 = calculate_mse(T_06, estimated_matrix_06)\n",
        "print(\"MSE for FashionMNIST0.6:\", mse_06)"
      ],
      "metadata": {
        "id": "RVGZrfBCOAFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e347e3-80b7-4ab4-a76d-e39dca1b4c96"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for FashionMNIST0.6: 0.0001615191981324255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Image Classification with Unknown Flip Rates"
      ],
      "metadata": {
        "id": "mvK4no3VKXbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 CNN for CIFAR dataset"
      ],
      "metadata": {
        "id": "wPmIdRvx7ml-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.1 without Transition Matrix"
      ],
      "metadata": {
        "id": "cfzMh-h-kSgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model for 32x32 RGB images\n",
        "class CNN32x32(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN32x32, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 3 input channels for RGB\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # After two pooling layers, the spatial dimensions will be reduced to 8x8\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Adjusted for 32x32 input size\n",
        "        self.fc2 = nn.Linear(512, 4)  # Assuming 4 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # First convolution + pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Second convolution + pooling\n",
        "        x = x.view(-1, 64 * 8 * 8)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))      # Fully connected layer\n",
        "        x = self.fc2(x)              # Output layer\n",
        "        return x\n",
        "\n",
        "# Standard training and evaluation function\n",
        "def train_and_evaluate(model_class, X, y, epochs=10, batch_size=64):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "\n",
        "    # Convert data to PyTorch Tensors and rearrange axes to (N, C, H, W)\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    # Calculate mean and standard deviation per channel from training data\n",
        "    mean = X_train_tensor.mean(dim=(0, 2, 3), keepdim=True)\n",
        "    std = X_train_tensor.std(dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "    # Normalize the training and validation data\n",
        "    X_train_tensor = (X_train_tensor - mean) / std\n",
        "    X_val_tensor = (X_val_tensor - mean) / std\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_class().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, targets in train_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)  # Standard cross-entropy loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy = evaluate_model(model, val_loader)\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    return model, mean, std\n",
        "\n",
        "def evaluate_on_test_set(model, X_test, y_test, mean, std, batch_size=64):\n",
        "    # Convert test data to PyTorch Tensors and rearrange axes\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    X_test_tensor = (X_test_tensor - mean) / std  # Normalize using training set mean and std\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Lp7OG2utkQ8p"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test_accuracy_10, std_test_accuracy_10 = train_multiple_times_with_test(\n",
        "    CNN32x32, Xtr_C10, Str_C10, Xts_C10, Yts_C10, num_trials=10, epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "kP-0pFnrhvVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ee7730-94ca-4203-e27f-a089b51c7161"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.0199\n",
            "Epoch 2/5, Loss: 0.8443\n",
            "Epoch 3/5, Loss: 0.7681\n",
            "Epoch 4/5, Loss: 0.6995\n",
            "Epoch 5/5, Loss: 0.6287\n",
            "Validation Accuracy: 71.33%\n",
            "Test Accuracy: 80.15%\n",
            "Trial 1 Test Accuracy: 80.15%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9872\n",
            "Epoch 2/5, Loss: 0.8372\n",
            "Epoch 3/5, Loss: 0.7653\n",
            "Epoch 4/5, Loss: 0.7105\n",
            "Epoch 5/5, Loss: 0.6298\n",
            "Validation Accuracy: 69.53%\n",
            "Test Accuracy: 79.17%\n",
            "Trial 2 Test Accuracy: 79.17%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9857\n",
            "Epoch 2/5, Loss: 0.8172\n",
            "Epoch 3/5, Loss: 0.7466\n",
            "Epoch 4/5, Loss: 0.6742\n",
            "Epoch 5/5, Loss: 0.5971\n",
            "Validation Accuracy: 69.62%\n",
            "Test Accuracy: 79.33%\n",
            "Trial 3 Test Accuracy: 79.33%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9680\n",
            "Epoch 2/5, Loss: 0.8164\n",
            "Epoch 3/5, Loss: 0.7430\n",
            "Epoch 4/5, Loss: 0.6662\n",
            "Epoch 5/5, Loss: 0.5811\n",
            "Validation Accuracy: 66.67%\n",
            "Test Accuracy: 75.53%\n",
            "Trial 4 Test Accuracy: 75.53%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9966\n",
            "Epoch 2/5, Loss: 0.8289\n",
            "Epoch 3/5, Loss: 0.7520\n",
            "Epoch 4/5, Loss: 0.6879\n",
            "Epoch 5/5, Loss: 0.5986\n",
            "Validation Accuracy: 69.47%\n",
            "Test Accuracy: 79.40%\n",
            "Trial 5 Test Accuracy: 79.40%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9746\n",
            "Epoch 2/5, Loss: 0.8174\n",
            "Epoch 3/5, Loss: 0.7336\n",
            "Epoch 4/5, Loss: 0.6553\n",
            "Epoch 5/5, Loss: 0.5597\n",
            "Validation Accuracy: 69.90%\n",
            "Test Accuracy: 79.03%\n",
            "Trial 6 Test Accuracy: 79.03%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9985\n",
            "Epoch 2/5, Loss: 0.8242\n",
            "Epoch 3/5, Loss: 0.7605\n",
            "Epoch 4/5, Loss: 0.6846\n",
            "Epoch 5/5, Loss: 0.6153\n",
            "Validation Accuracy: 68.58%\n",
            "Test Accuracy: 78.55%\n",
            "Trial 7 Test Accuracy: 78.55%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9988\n",
            "Epoch 2/5, Loss: 0.8355\n",
            "Epoch 3/5, Loss: 0.7683\n",
            "Epoch 4/5, Loss: 0.7027\n",
            "Epoch 5/5, Loss: 0.6406\n",
            "Validation Accuracy: 70.20%\n",
            "Test Accuracy: 78.65%\n",
            "Trial 8 Test Accuracy: 78.65%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9896\n",
            "Epoch 2/5, Loss: 0.8226\n",
            "Epoch 3/5, Loss: 0.7470\n",
            "Epoch 4/5, Loss: 0.6765\n",
            "Epoch 5/5, Loss: 0.5879\n",
            "Validation Accuracy: 68.25%\n",
            "Test Accuracy: 77.80%\n",
            "Trial 9 Test Accuracy: 77.80%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 0.9760\n",
            "Epoch 2/5, Loss: 0.8198\n",
            "Epoch 3/5, Loss: 0.7490\n",
            "Epoch 4/5, Loss: 0.6718\n",
            "Epoch 5/5, Loss: 0.5919\n",
            "Validation Accuracy: 68.78%\n",
            "Test Accuracy: 79.58%\n",
            "Trial 10 Test Accuracy: 79.58%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 78.72%\n",
            "Standard Deviation of Test Accuracy: 1.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.2 with Transition Matrix"
      ],
      "metadata": {
        "id": "eQB_XVdPkRw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model_class, X, y, transition_matrix, epochs=10, batch_size=64):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "\n",
        "    # Convert data to PyTorch Tensors and rearrange axes to (N, C, H, W)\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    # Calculate mean and standard deviation per channel from training data\n",
        "    mean = X_train_tensor.mean(dim=(0, 2, 3), keepdim=True)\n",
        "    std = X_train_tensor.std(dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "    # Normalize the training and validation data\n",
        "    X_train_tensor = (X_train_tensor - mean) / std\n",
        "    X_val_tensor = (X_val_tensor - mean) / std\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_class().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, targets in train_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = noisy_loss_function(outputs, targets, transition_matrix)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    accuracy = evaluate_model(model, val_loader)\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    return model, mean, std"
      ],
      "metadata": {
        "id": "UAHRPP1ChvOM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_T = [[0.85, 0.018, 0.02725, 0.10475],\n",
        " [0.07763158, 0.91763158, 0.00210526, 0.00263158],\n",
        " [0.02464363, 0.14085528, 0.80985745, 0.02464363],\n",
        " [0.01093643, 0.00341763, 0.09603554, 0.88961039]]"
      ],
      "metadata": {
        "id": "gxZWl3nVrtMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the  dataset\n",
        "mean_test_accuracy_10, std_test_accuracy_10 = train_multiple_times_with_test_withT(\n",
        "    CNN32x32, Xtr_C10, Str_C10, Xts_C10, Yts_C10, estimated_T, num_trials=10, epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvtaQ4LqoCcY",
        "outputId": "02755f5a-e37a-4326-f799-bb97d8e5ac55"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1020\n",
            "Epoch 2/5, Loss: 1.0010\n",
            "Epoch 3/5, Loss: 0.9550\n",
            "Epoch 4/5, Loss: 0.9167\n",
            "Epoch 5/5, Loss: 0.8692\n",
            "Validation Accuracy: 69.17%\n",
            "Test Accuracy: 80.67%\n",
            "Trial 1 Test Accuracy: 80.67%\n",
            "\n",
            "Trial 2/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1156\n",
            "Epoch 2/5, Loss: 1.0080\n",
            "Epoch 3/5, Loss: 0.9643\n",
            "Epoch 4/5, Loss: 0.9220\n",
            "Epoch 5/5, Loss: 0.8750\n",
            "Validation Accuracy: 68.40%\n",
            "Test Accuracy: 78.53%\n",
            "Trial 2 Test Accuracy: 78.53%\n",
            "\n",
            "Trial 3/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1139\n",
            "Epoch 2/5, Loss: 1.0168\n",
            "Epoch 3/5, Loss: 0.9735\n",
            "Epoch 4/5, Loss: 0.9379\n",
            "Epoch 5/5, Loss: 0.9003\n",
            "Validation Accuracy: 68.55%\n",
            "Test Accuracy: 78.40%\n",
            "Trial 3 Test Accuracy: 78.40%\n",
            "\n",
            "Trial 4/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1265\n",
            "Epoch 2/5, Loss: 1.0201\n",
            "Epoch 3/5, Loss: 0.9802\n",
            "Epoch 4/5, Loss: 0.9407\n",
            "Epoch 5/5, Loss: 0.9012\n",
            "Validation Accuracy: 68.97%\n",
            "Test Accuracy: 77.85%\n",
            "Trial 4 Test Accuracy: 77.85%\n",
            "\n",
            "Trial 5/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1364\n",
            "Epoch 2/5, Loss: 1.0173\n",
            "Epoch 3/5, Loss: 0.9724\n",
            "Epoch 4/5, Loss: 0.9340\n",
            "Epoch 5/5, Loss: 0.8936\n",
            "Validation Accuracy: 67.62%\n",
            "Test Accuracy: 78.62%\n",
            "Trial 5 Test Accuracy: 78.62%\n",
            "\n",
            "Trial 6/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1508\n",
            "Epoch 2/5, Loss: 1.0260\n",
            "Epoch 3/5, Loss: 0.9830\n",
            "Epoch 4/5, Loss: 0.9443\n",
            "Epoch 5/5, Loss: 0.9034\n",
            "Validation Accuracy: 69.65%\n",
            "Test Accuracy: 80.78%\n",
            "Trial 6 Test Accuracy: 80.78%\n",
            "\n",
            "Trial 7/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1018\n",
            "Epoch 2/5, Loss: 1.0089\n",
            "Epoch 3/5, Loss: 0.9616\n",
            "Epoch 4/5, Loss: 0.9134\n",
            "Epoch 5/5, Loss: 0.8644\n",
            "Validation Accuracy: 67.90%\n",
            "Test Accuracy: 78.22%\n",
            "Trial 7 Test Accuracy: 78.22%\n",
            "\n",
            "Trial 8/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1019\n",
            "Epoch 2/5, Loss: 1.0027\n",
            "Epoch 3/5, Loss: 0.9563\n",
            "Epoch 4/5, Loss: 0.9132\n",
            "Epoch 5/5, Loss: 0.8648\n",
            "Validation Accuracy: 68.45%\n",
            "Test Accuracy: 79.30%\n",
            "Trial 8 Test Accuracy: 79.30%\n",
            "\n",
            "Trial 9/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1031\n",
            "Epoch 2/5, Loss: 1.0098\n",
            "Epoch 3/5, Loss: 0.9681\n",
            "Epoch 4/5, Loss: 0.9225\n",
            "Epoch 5/5, Loss: 0.8749\n",
            "Validation Accuracy: 68.65%\n",
            "Test Accuracy: 79.75%\n",
            "Trial 9 Test Accuracy: 79.75%\n",
            "\n",
            "Trial 10/10\n",
            "X_train shape: (16000, 32, 32, 3)\n",
            "y_train shape: (16000,)\n",
            "Unique labels in y_train: [0 1 2 3]\n",
            "Epoch 1/5, Loss: 1.1250\n",
            "Epoch 2/5, Loss: 1.0218\n",
            "Epoch 3/5, Loss: 0.9762\n",
            "Epoch 4/5, Loss: 0.9370\n",
            "Epoch 5/5, Loss: 0.8937\n",
            "Validation Accuracy: 69.30%\n",
            "Test Accuracy: 79.75%\n",
            "Trial 10 Test Accuracy: 79.75%\n",
            "\n",
            "Average Test Accuracy after 10 trials: 79.19%\n",
            "Standard Deviation of Test Accuracy: 0.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Logistic Regression for CIFAR dataset"
      ],
      "metadata": {
        "id": "Al1DSx29olu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(X_tr, S_tr, X_ts, Y_ts, estimated_T):\n",
        "    # Initialize lists to store accuracy results for validation and test sets\n",
        "    acc_valid_list = []\n",
        "    acc_test_without_T_list = []\n",
        "    acc_test_with_T_list = []\n",
        "\n",
        "    # Run multiple training and evaluation iterations\n",
        "    for i in range(10):\n",
        "        # Split the training data into training and validation sets\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X_tr, S_tr, test_size=0.2, shuffle=True)\n",
        "\n",
        "        # Flatten the data to convert image data into a 2D matrix\n",
        "        X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "        X_valid_flat = X_valid.reshape(X_valid.shape[0], -1)\n",
        "        X_ts_flat = X_ts.reshape(X_ts.shape[0], -1)\n",
        "\n",
        "        # Initialize and train the logistic model\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train_flat, y_train)\n",
        "\n",
        "        # Predict and calculate accuracy on the validation set\n",
        "        y_pred = model.predict(X_valid_flat)\n",
        "        acc_valid = accuracy_score(y_pred, y_valid)\n",
        "        acc_valid_list.append(acc_valid)\n",
        "\n",
        "        # Predict and calculate accuracy on the test set (without transition matrix)\n",
        "        y_pred = model.predict(X_ts_flat)\n",
        "        acc_test_without_T = accuracy_score(y_pred, Y_ts)\n",
        "        acc_test_without_T_list.append(acc_test_without_T)\n",
        "\n",
        "        # Calculate accuracy on the test set using the transition matrix\n",
        "        prob = model.predict_proba(X_ts_flat)\n",
        "        prob = np.dot(np.linalg.inv(estimated_T), prob.T).T  # Apply transition matrix\n",
        "        y_pred = np.argmax(prob, axis=1)\n",
        "        acc_test_with_T = accuracy_score(y_pred, Y_ts)\n",
        "        acc_test_with_T_list.append(acc_test_with_T)\n",
        "\n",
        "        # Print accuracy for each iteration\n",
        "        print(\"Current epoch: %d, Accuracy on valid set: %.4f%%, accuracy on test set without Transition Matrix: %.4f%%, accuracy on test set with Transition Matrix: %.4f%%\"\n",
        "              % (i+1, acc_valid * 100, acc_test_without_T * 100, acc_test_with_T * 100))\n",
        "\n",
        "    # Calculate and print the mean and standard deviation for validation and test set accuracies\n",
        "    print(\"Mean on valid set: %.4f, Mean on test set without Transition Matrix: %.4f, Mean on test set with Transition Matrix: %.4f\"\n",
        "          % (np.mean(acc_valid_list), np.mean(acc_test_without_T_list), np.mean(acc_test_with_T_list)))\n",
        "\n",
        "    print(\"Std on valid set: %.4f, Std on test set without Transition Matrix: %.4f, Std on test set with Transition Matrix: %.4f\"\n",
        "          % (np.std(acc_valid_list), np.std(acc_test_without_T_list), np.std(acc_test_with_T_list)))\n",
        "\n",
        "# Assume X_tr, S_tr, X_ts, and Y_ts are defined\n",
        "logistic_10 = logistic(Xtr_C10, Str_C10, Xts_C10, Yts_C10, estimated_T)\n",
        "logistic_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csVCJhFE5TtJ",
        "outputId": "5a7a4843-7ec0-4c86-d9a8-e71a98269cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current epoch: 1, Accuracy on valid set: 53.3750%, accuracy on test set without Transition Matrix: 59.8000%, accuracy on test set with Transition Matrix: 60.0250%\n",
            "Current epoch: 2, Accuracy on valid set: 54.0750%, accuracy on test set without Transition Matrix: 59.6000%, accuracy on test set with Transition Matrix: 60.1000%\n",
            "Current epoch: 3, Accuracy on valid set: 53.8000%, accuracy on test set without Transition Matrix: 60.1750%, accuracy on test set with Transition Matrix: 60.6250%\n",
            "Current epoch: 4, Accuracy on valid set: 52.8500%, accuracy on test set without Transition Matrix: 60.2750%, accuracy on test set with Transition Matrix: 60.4500%\n",
            "Current epoch: 5, Accuracy on valid set: 52.6500%, accuracy on test set without Transition Matrix: 60.8250%, accuracy on test set with Transition Matrix: 61.2500%\n",
            "Current epoch: 6, Accuracy on valid set: 54.0250%, accuracy on test set without Transition Matrix: 60.2500%, accuracy on test set with Transition Matrix: 60.9250%\n",
            "Current epoch: 7, Accuracy on valid set: 52.7750%, accuracy on test set without Transition Matrix: 60.3000%, accuracy on test set with Transition Matrix: 60.6750%\n",
            "Current epoch: 8, Accuracy on valid set: 53.9500%, accuracy on test set without Transition Matrix: 59.7500%, accuracy on test set with Transition Matrix: 60.2500%\n",
            "Current epoch: 9, Accuracy on valid set: 52.0500%, accuracy on test set without Transition Matrix: 59.6250%, accuracy on test set with Transition Matrix: 59.7500%\n",
            "Current epoch: 10, Accuracy on valid set: 53.4500%, accuracy on test set without Transition Matrix: 59.7250%, accuracy on test set with Transition Matrix: 60.1750%\n",
            "Mean on valid set: 0.5330, Mean on test set without Transition Matrix: 0.6003, Mean on test set with Transition Matrix: 0.6042\n",
            "Std on valid set: 0.0065, Std on test set without Transition Matrix: 0.0038, Std on test set with Transition Matrix: 0.0043\n"
          ]
        }
      ]
    }
  ]
}